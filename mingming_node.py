# -*- coding: utf-8 -*-
"""
Mingming LoRA Maker â€” ComfyUI Custom Node
ğŸ’– Input â†’ ğŸ’™ 360Â° Preview â†’ ğŸ’œ Training
Simple 3-node workflow for LoRA creation

ì´ë²ˆ ìˆ˜ì •:
â€¢ 2ë²ˆ ë…¸ë“œ(í”„ë¦¬ë·°)ì— ì™„(Wan) ì—°ê²°ìš© I/O ì¶”ê°€
  - ğŸŸ¢_í”„ë¡¬í”„íŠ¸ / ğŸ”´_ë¶€ì •í”„ë¡¬í”„íŠ¸
  - ğŸ§ª_seed / ğŸ§ª_steps / ğŸ§ª_cfg / ğŸ§ª_sampler / ğŸ§ª_scheduler
â€¢ 2ë²ˆ ë…¸ë“œ ì¶œë ¥ í™•ì¥:
  frames_batch, generation_info, pos_prompt, neg_prompt, seed, steps, cfg, sampler_name, scheduler
â†’ CLIPTextEncode(+/âˆ’), KSamplerì— ë°”ë¡œ ì—°ê²° ê°€ëŠ¥
"""

import os
import json
import math
import datetime
import re
import numpy as np
from PIL import Image, ImageOps, ImageDraw, ImageFont
import folder_paths

# ---------- Utility Functions ----------

def _ensure_dir(path: str):
    """ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
    if path and not os.path.exists(path):
        os.makedirs(path, exist_ok=True)

def _timestamp() -> str:
    """í˜„ì¬ ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„"""
    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

def _pkg_root() -> str:
    """íŒ¨í‚¤ì§€ ë£¨íŠ¸ ë””ë ‰í† ë¦¬"""
    return os.path.dirname(os.path.abspath(__file__))

def _pkg_data_root() -> str:
    """ë°ì´í„° ì €ì¥ ë£¨íŠ¸ ë””ë ‰í† ë¦¬"""
    root = os.path.join(_pkg_root(), "data")
    _ensure_dir(root)
    return root

def _sanitize_name(name: str) -> str:
    """íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    name = (name or "").strip().replace(" ", "_")
    return re.sub(r"[^0-9A-Za-zê°€-í£._-]", "", name) or "mingming_lora"

def _expand_path(path: str) -> str:
    """í™˜ê²½ë³€ìˆ˜ ë° ~ ê²½ë¡œ í™•ì¥"""
    if not path:
        return ""
    return os.path.expanduser(os.path.expandvars(path))

# ---------- ğŸ’– INPUT NODE ----------

class MingmingInputNode:
    """
    ì…ë ¥ ë…¸ë“œ - LoRA ê¸°ë³¸ ì„¤ì • ë° ì†ŒìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬
    """
    @classmethod
    def INPUT_TYPES(cls):
        # ComfyUI ì…ë ¥ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        input_dir = folder_paths.get_input_directory()
        try:
            files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]
            files = sorted([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.mp4', '.avi', '.mov'))])
        except:
            files = []
        if not files:
            files = ["<no_files>"]

        return {
            "required": {
                "ğŸ’–_ë¡œë¼_ì´ë¦„": ("STRING", {"default": "mingming", "multiline": False}),
                "ğŸ’—_íŠ¸ë¦¬ê±°_ì›Œë“œ": ("STRING", {"default": "ming", "multiline": False}),
                "ğŸ’•_ìŠ¤íƒ€ì¼": ([
                    "ğŸ’– cute_style",
                    "ğŸ’™ anime_style",
                    "ğŸ’œ realistic_style",
                    "ğŸ§¡ fantasy_style"
                ], {"default": "ğŸ’– cute_style"}),
                "ğŸ’“_í’ˆì§ˆ_íƒœê·¸": ("STRING", {
                    "default": "high quality, detailed, masterpiece",
                    "multiline": True
                }),
                "ğŸ’˜_ì†ŒìŠ¤_íƒ€ì…": ([
                    "single_image",
                    "video_frames",
                    "manual_input"
                ], {"default": "single_image"}),
                "ğŸ’_ì†ŒìŠ¤_íŒŒì¼": (files,),
            },
            "optional": {
                "input_image": ("IMAGE",),
                "video_path": ("STRING", {"default": ""}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("source_image",)
    FUNCTION = "process_input"
    CATEGORY = "ğŸ’– Mingming LoRA"
    OUTPUT_NODE = False

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return float("nan")  # í•­ìƒ ë³€ê²½ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¯¸ë¦¬ë³´ê¸° ì—…ë°ì´íŠ¸

    def process_input(self, **kwargs):
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        lora_name = _sanitize_name(kwargs.get("ğŸ’–_ë¡œë¼_ì´ë¦„", "mingming"))
        trigger_word = kwargs.get("ğŸ’—_íŠ¸ë¦¬ê±°_ì›Œë“œ", "ming").strip()
        style = kwargs.get("ğŸ’•_ìŠ¤íƒ€ì¼", "ğŸ’– cute_style")
        quality_tags = kwargs.get("ğŸ’“_í’ˆì§ˆ_íƒœê·¸", "high quality, detailed, masterpiece")
        source_type = kwargs.get("ğŸ’˜_ì†ŒìŠ¤_íƒ€ì…", "single_image")
        common_caption = kwargs.get("ğŸ’›_ê³µí†µ_ìº¡ì…˜", "")
        data_path = kwargs.get("ğŸ’š_ë°ì´í„°_ê²½ë¡œ", "AUTO")

        # ì˜µì…”ë„ íŒŒë¼ë¯¸í„°
        source_file = kwargs.get("ğŸ’_ì†ŒìŠ¤_íŒŒì¼")
        input_image = kwargs.get("input_image")
        video_path = kwargs.get("video_path", "")

        # ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •
        if data_path == "AUTO" or not data_path.strip():
            dataset_path = os.path.join(_pkg_data_root(), lora_name)
        else:
            dataset_path = _expand_path(data_path)
        _ensure_dir(dataset_path)

        # ì†ŒìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬
        source_image = self._process_source_image(
            source_type, source_file, input_image, video_path, lora_name, trigger_word
        )

        print(f"ğŸ’– Mingming Input processed: {lora_name} | {trigger_word} | {style}")

        return {
            "ui": {"images": self._get_preview_images(source_image)},
            "result": (source_image,)
        }

    def _process_source_image(self, source_type, source_file, input_image, video_path, lora_name, trigger_word):
        """ì†ŒìŠ¤ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§"""
        # 2. íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
        if source_file and source_file != "<no_files>":
            try:
                input_dir = folder_paths.get_input_directory()
                file_path = os.path.join(input_dir, source_file)
                if os.path.exists(file_path):
                    img = Image.open(file_path)
                    img = ImageOps.exif_transpose(img)  # EXIF íšŒì „ ì •ë³´ ì ìš©
                    img_array = np.array(img).astype(np.float32) / 255.0
                    if len(img_array.shape) == 2:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                        img_array = np.stack([img_array] * 3, axis=-1)
                    return img_array[None, ...]  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            except Exception as e:
                print(f"ğŸ’– íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")

        # 1. ì—…ìŠ¤íŠ¸ë¦¼ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš© (ì„ íƒì )
        if input_image is not None:
            return input_image

        # 3. ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ì²« í”„ë ˆì„ ì¶”ì¶œ)
        if source_type == "video_frames" and video_path:
            try:
                import cv2
                cap = cv2.VideoCapture(video_path)
                ret, frame = cap.read()
                if ret:
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    img_array = np.array(frame).astype(np.float32) / 255.0
                    cap.release()
                    return img_array[None, ...]
                cap.release()
            except ImportError:
                print("ğŸ’– OpenCV not available for video processing")
            except Exception as e:
                print(f"ğŸ’– ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # 4. ê¸°ë³¸ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        return self._create_dummy_image(lora_name, trigger_word)

    def _create_dummy_image(self, lora_name, trigger_word):
        """ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±"""
        img = Image.new('RGB', (512, 512), color=(200, 220, 255))
        draw = ImageDraw.Draw(img)
        try:
            font = ImageFont.load_default()
            text_lines = [f"ğŸ’– {lora_name}", f"ğŸ’— {trigger_word}", "Ready for 360Â° generation!"]
            y_start = 200
            for i, line in enumerate(text_lines):
                bbox = draw.textbbox((0, 0), line, font=font)
                text_width = bbox[2] - bbox[0]
                x = (512 - text_width) // 2
                y = y_start + i * 30
                draw.text((x+2, y+2), line, fill=(100, 100, 100), font=font)  # shadow
                draw.text((x, y), line, fill=(50, 50, 50), font=font)
        except Exception as e:
            print(f"ğŸ’– í…ìŠ¤íŠ¸ ë Œë”ë§ ì‹¤íŒ¨: {e}")
        img_array = np.array(img).astype(np.float32) / 255.0
        return img_array[None, ...]

    def _get_preview_images(self, source_image):
        """ë¯¸ë¦¬ë³´ê¸°ìš© ì´ë¯¸ì§€ ë°ì´í„° ë°˜í™˜"""
        try:
            if source_image is not None:
                img_array = source_image.cpu().numpy() if hasattr(source_image, 'cpu') else source_image
                img_uint8 = (np.clip(img_array[0] * 255.0, 0, 255)).astype(np.uint8)
                from PIL import Image
                from io import BytesIO
                pil_img = Image.fromarray(img_uint8)
                buffer = BytesIO()
                pil_img.save(buffer, format='PNG')
                return [{
                    "filename": "preview.png",
                    "subfolder": "",
                    "type": "temp",
                    "format": "PNG"
                }]
        except Exception as e:
            print(f"ğŸ’– Preview generation failed: {e}")
        return []

# ---------- ğŸ’™ 360Â° PREVIEW NODE (ì™„ + CLIP + ë¶€ì •í”„ë¡¬í”„íŠ¸ + KSampler I/O) ----------

class Mingming360PreviewNode:
    """
    360ë„ í”„ë¦¬ë·° ìƒì„± ë…¸ë“œ - ë‹¤ì–‘í•œ ê°ë„ì˜ ì´ë¯¸ì§€ ìƒì„± ë° ë°ì´í„°ì…‹ ì €ì¥
    + ì™„(Wan) íŒŒì´í”„ë¼ì¸ ì—°ê²°ì„ ìœ„í•œ Prompt/Negative/Sampler íŒŒë¼ë¯¸í„° I/O ì¶”ê°€

    ì¶œë ¥:
      frames_batch (IMAGE)
      generation_info (STRING)
      pos_prompt (STRING)
      neg_prompt (STRING)
      seed (INT)
      steps (INT)
      cfg (FLOAT)
      sampler_name (STRING)
      scheduler (STRING)
    """
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "source_image": ("IMAGE", {"forceInput": True}),
                "ğŸ’–_ë¡œë¼_ì´ë¦„": ("STRING", {"default": "mingming", "multiline": False}),
                "ğŸ’—_íŠ¸ë¦¬ê±°_ì›Œë“œ": ("STRING", {"default": "ming", "multiline": False}),
                "ğŸ’•_ìŠ¤íƒ€ì¼": ([
                    "ğŸ’– cute_style",
                    "ğŸ’™ anime_style",
                    "ğŸ’œ realistic_style",
                    "ğŸ§¡ fantasy_style"
                ], {"default": "ğŸ’– cute_style"}),
                "ğŸ’“_í’ˆì§ˆ_íƒœê·¸": ("STRING", {
                    "default": "high quality, detailed, masterpiece",
                    "multiline": True
                }),
                "ğŸ’›_ê³µí†µ_ìº¡ì…˜": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "ê³µí†µìœ¼ë¡œ ë“¤ì–´ê°ˆ ìº¡ì…˜ ë‚´ìš©..."
                }),
                "ğŸ’š_ë°ì´í„°_ê²½ë¡œ": ("STRING", {
                    "default": "AUTO",
                    "multiline": False,
                    "placeholder": "AUTO ë˜ëŠ” ì‚¬ìš©ì ê²½ë¡œ"
                }),
                "ğŸ’™_í”„ë ˆì„_ìˆ˜": ("INT", {"default": 15, "min": 4, "max": 72, "step": 1}),
                "ğŸ’œ_ì´ë¯¸ì§€_í¬ê¸°": (["512x512","768x768","1024x1024"], {"default": "768x768"}),
                "ğŸ’_ìƒì„±_í’ˆì§ˆ": (["draft","normal","high","ultra"], {"default": "normal"}),
                "ğŸ§¡_ìë™_ì €ì¥": ("BOOLEAN", {"default": True}),
                "ğŸ’˜_ê·¸ë¦¬ë“œ_í”„ë¦¬ë·°": ("BOOLEAN", {"default": True}),
                "ğŸ¤_ê°ë„_ëœë¤": ("BOOLEAN", {"default": False}),
                # ---- WAN ì—°ê²°ìš© I/O ----
                "ğŸŸ¢_í”„ë¡¬í”„íŠ¸": ("STRING", {"default": "a cute anime girl, full body, looking at camera"}),
                "ğŸ”´_ë¶€ì •í”„ë¡¬í”„íŠ¸": ("STRING", {"default": "worst quality, low quality, jpeg artifacts, deformed, extra fingers"}),
                "ğŸ§ª_seed": ("INT", {"default": 123456789}),
                "ğŸ§ª_steps": ("INT", {"default": 20, "min": 1, "max": 100}),
                "ğŸ§ª_cfg": ("FLOAT", {"default": 6.0, "min": 0.1, "max": 20.0}),
                "ğŸ§ª_sampler": (["euler","euler_ancestral","uni_pc","dpmpp_2m"], {"default": "uni_pc"}),
                "ğŸ§ª_scheduler": (["simple","karras","sgm_uniform"], {"default": "simple"}),
            }
        }

    RETURN_TYPES = ("IMAGE","STRING","STRING","STRING","INT","INT","FLOAT","STRING","STRING")
    RETURN_NAMES  = ("frames_batch","generation_info","pos_prompt","neg_prompt","seed","steps","cfg","sampler_name","scheduler")
    FUNCTION = "generate_360_preview"
    CATEGORY = "ğŸ’– Mingming LoRA"
    OUTPUT_NODE = False

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return float("nan")

    def generate_360_preview(self, source_image, **kwargs):
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        lora_name = _sanitize_name(kwargs.get("ğŸ’–_ë¡œë¼_ì´ë¦„", "mingming"))
        trigger_word = kwargs.get("ğŸ’—_íŠ¸ë¦¬ê±°_ì›Œë“œ", "ming")
        style = kwargs.get("ğŸ’•_ìŠ¤íƒ€ì¼", "ğŸ’– cute_style")
        quality_tags = kwargs.get("ğŸ’“_í’ˆì§ˆ_íƒœê·¸", "high quality, detailed, masterpiece")
        common_caption = kwargs.get("ğŸ’›_ê³µí†µ_ìº¡ì…˜", "")
        data_path = kwargs.get("ğŸ’š_ë°ì´í„°_ê²½ë¡œ", "AUTO")

        frame_count = kwargs.get("ğŸ’™_í”„ë ˆì„_ìˆ˜", 15)
        image_size = kwargs.get("ğŸ’œ_ì´ë¯¸ì§€_í¬ê¸°", "768x768")
        quality = kwargs.get("ğŸ’_ìƒì„±_í’ˆì§ˆ", "normal")
        auto_save = kwargs.get("ğŸ§¡_ìë™_ì €ì¥", True)
        show_grid = kwargs.get("ğŸ’˜_ê·¸ë¦¬ë“œ_í”„ë¦¬ë·°", True)
        random_angles = kwargs.get("ğŸ¤_ê°ë„_ëœë¤", False)

        # WAN ì—°ê²° I/O ê°’
        pos_prompt = kwargs.get("ğŸŸ¢_í”„ë¡¬í”„íŠ¸","")
        neg_prompt = kwargs.get("ğŸ”´_ë¶€ì •í”„ë¡¬í”„íŠ¸","")
        seed       = kwargs.get("ğŸ§ª_seed", 123456789)
        steps      = kwargs.get("ğŸ§ª_steps", 20)
        cfg        = kwargs.get("ğŸ§ª_cfg", 6.0)
        sampler    = kwargs.get("ğŸ§ª_sampler","uni_pc")
        scheduler  = kwargs.get("ğŸ§ª_scheduler","simple")

        # ë°ì´í„°ì…‹ ê²½ë¡œ
        if data_path == "AUTO" or not data_path.strip():
            dataset_path = os.path.join(_pkg_data_root(), lora_name)
        else:
            dataset_path = _expand_path(data_path)
        _ensure_dir(dataset_path)

        w, h = map(int, image_size.split('x'))

        # ê°ë„ ê³„ì‚°
        if random_angles:
            import random
            angles = sorted([random.uniform(0, 360) for _ in range(frame_count)])
        else:
            angles = [i * (360.0 / frame_count) for i in range(frame_count)]

        # ì†ŒìŠ¤ ì´ë¯¸ì§€
        source_array = source_image.cpu().numpy() if hasattr(source_image, 'cpu') else source_image
        base_img = Image.fromarray((np.clip(source_array[0] * 255.0, 0, 255)).astype(np.uint8))

        # 360ë„ í”„ë ˆì„ ìƒì„±
        frames, saved_files = [], []
        print(f"ğŸ’™ Generating {frame_count} frames for 360Â° preview...")
        for i, angle in enumerate(angles):
            frame_img = self._generate_angle_frame(base_img, angle, w, h, lora_name, trigger_word, quality)
            frame_array = np.array(frame_img).astype(np.float32) / 255.0
            frames.append(frame_array)

            if auto_save:
                img_filename = f"{lora_name}_{i+1:03d}.png"
                img_path = os.path.join(dataset_path, img_filename)
                frame_img.save(img_path)
                caption = self._generate_caption(trigger_word, lora_name, style, quality_tags, angle, i)
                txt_filename = f"{lora_name}_{i+1:03d}.txt"
                txt_path = os.path.join(dataset_path, txt_filename)
                with open(txt_path, 'w', encoding='utf-8') as f:
                    f.write(caption)
                saved_files.append(f"{img_filename} + {txt_filename}")

            if (i + 1) % 5 == 0 or i == len(angles) - 1:
                print(f"ğŸ’™ Progress: {i+1}/{frame_count} frames completed")

        frames_batch = np.stack(frames, axis=0)

        # í”„ë¦¬ë·° ê·¸ë¦¬ë“œ
        if show_grid and len(frames) > 1:
            preview_grid = self._create_preview_grid(frames, frame_count)
            preview_grid_array = np.array(preview_grid).astype(np.float32) / 255.0
            preview_grid_batch = preview_grid_array[None, ...]
        else:
            preview_grid_batch = frames_batch[0:1]

        generation_info = f"""ğŸ’™ 360ë„ í”„ë¦¬ë·° ìƒì„± ì™„ë£Œ!

ğŸ’– LoRA Name: {lora_name}
ğŸ’— Trigger Word: {trigger_word}
ğŸ’™ Total Frames: {frame_count}
ğŸ’š Image Size: {image_size}
ğŸ’œ Quality: {quality}
ğŸ’ Auto Save: {'ON' if auto_save else 'OFF'}
ğŸ’• Dataset Path: {dataset_path}

ğŸ§ª Sampler:
  seed={seed}, steps={steps}, cfg={cfg}, sampler={sampler}, scheduler={scheduler}

ğŸ§¡ Generated Files: {len(saved_files)} pairs
{"ğŸ“ " + chr(10).join(saved_files[:5]) if saved_files else ""}
{"..." if len(saved_files) > 5 else ""}"""

        print(f"ğŸ’™ 360Â° preview generation completed: {frame_count} frames")

        return {
            "ui": {"images": self._get_360_preview_images(frames_batch, preview_grid_batch, frame_count)},
            "result": (frames_batch, generation_info, pos_prompt, neg_prompt, seed, steps, cfg, sampler, scheduler)
        }

    def _generate_angle_frame(self, base_img, angle, w, h, lora_name, trigger_word, quality):
        """ê°ë„ë³„ í”„ë ˆì„ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)"""
        frame = base_img.resize((w, h), Image.LANCZOS)
        if quality == "draft":
            frame = frame.resize((w//2, h//2), Image.LANCZOS).resize((w, h), Image.NEAREST)
        elif quality == "ultra":
            frame = frame.filter(Image.SHARPEN)
        self._add_angle_overlay(frame, angle, lora_name, trigger_word)
        return frame

    def _add_angle_overlay(self, img, angle, lora_name, trigger_word):
        draw = ImageDraw.Draw(img)
        try:
            font = ImageFont.load_default()
            angle_text = f"{angle:.1f}Â°"
            bbox = draw.textbbox((0, 0), angle_text, font=font)
            box_w = bbox[2] - bbox[0] + 20
            box_h = bbox[3] - bbox[1] + 10
            overlay = Image.new('RGBA', img.size, (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            overlay_draw.rectangle([10, 10, 10 + box_w, 10 + box_h], fill=(0, 0, 0, 128))
            img.paste(Image.alpha_composite(img.convert('RGBA'), overlay).convert('RGB'))
            draw = ImageDraw.Draw(img)
            draw.text((20, 15), angle_text, fill='white', font=font)
            info_text = f"ğŸ’— {trigger_word}"
            img_w, img_h = img.size
            info_bbox = draw.textbbox((0, 0), info_text, font=font)
            info_w = info_bbox[2] - info_bbox[0]
            draw.text((img_w - info_w - 20, img_h - 30), info_text, fill='white', font=font)
        except Exception as e:
            print(f"ğŸ’™ ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")

    def _generate_caption(self, trigger_word, lora_name, style, tags, angle, frame_idx):
        caption_parts = []
        if trigger_word:
            caption_parts.append(trigger_word)
        lora_display = lora_name.replace('_', ' ')
        if lora_display and lora_display != trigger_word:
            caption_parts.append(lora_display)
        if "cute" in style.lower():
            style_tags = ["cute", "kawaii", "adorable"]
        elif "anime" in style.lower():
            style_tags = ["anime", "manga", "illustration"]
        elif "realistic" in style.lower():
            style_tags = ["realistic", "detailed", "photographic"]
        elif "fantasy" in style.lower():
            style_tags = ["fantasy", "magical", "ethereal"]
        else:
            style_tags = ["high quality"]
        caption_parts.extend(style_tags)
        if 315 <= angle or angle < 45:
            caption_parts.append("front view")
        elif 45 <= angle < 135:
            caption_parts.append("side view")
        elif 135 <= angle < 225:
            caption_parts.append("back view")
        elif 225 <= angle < 315:
            caption_parts.append("side view")
        if tags:
            ko_en_map = {
                "ê³ í’ˆì§ˆ": "high quality",
                "ì„¸ë°€í•œ": "detailed",
                "ê±¸ì‘": "masterpiece",
                "ì•„ë¦„ë‹¤ìš´": "beautiful",
                "ì˜ˆìœ": "pretty"
            }
            extra_tags = []
            for tag in tags.split(','):
                tag = tag.strip()
                if tag:
                    extra_tags.append(ko_en_map.get(tag, tag))
            caption_parts.extend(extra_tags)
        return ", ".join(caption_parts)

    def _create_preview_grid(self, frames, total_count):
        if not frames:
            return Image.new('RGB', (512, 512), 'black')
        cols = math.ceil(math.sqrt(total_count))
        rows = math.ceil(total_count / cols)
        thumb_size = 128
        grid_w, grid_h = cols * thumb_size, rows * thumb_size
        grid_img = Image.new('RGB', (grid_w, grid_h), (40, 40, 40))
        for i, frame_array in enumerate(frames):
            if i >= total_count:
                break
            frame_img = Image.fromarray((frame_array * 255).astype(np.uint8))
            thumb = frame_img.resize((thumb_size, thumb_size), Image.LANCZOS)
            row, col = divmod(i, cols)
            x, y = col * thumb_size, row * thumb_size
            grid_img.paste(thumb, (x, y))
        return grid_img

    def _get_360_preview_images(self, frames_batch, preview_grid_batch, frame_count):
        preview_images = []
        try:
            if preview_grid_batch is not None:
                grid_array = preview_grid_batch.cpu().numpy() if hasattr(preview_grid_batch, 'cpu') else preview_grid_batch
                grid_uint8 = (np.clip(grid_array[0] * 255.0, 0, 255)).astype(np.uint8)
                preview_images.append({
                    "filename": f"360_grid_preview_{frame_count}frames.png",
                    "subfolder": "",
                    "type": "temp",
                    "format": "PNG",
                    "image_data": grid_uint8
                })
            if frames_batch is not None:
                frames_array = frames_batch.cpu().numpy() if hasattr(frames_batch, 'cpu') else frames_batch
                preview_count = min(4, len(frames_array))
                for i in range(preview_count):
                    frame_uint8 = (np.clip(frames_array[i] * 255.0, 0, 255)).astype(np.uint8)
                    angle = i * (360.0 / frame_count)
                    preview_images.append({
                        "filename": f"frame_{i+1:03d}_{angle:.0f}deg.png",
                        "subfolder": "",
                        "type": "temp",
                        "format": "PNG",
                        "image_data": frame_uint8
                    })
        except Exception as e:
            print(f"ğŸ’™ 360Â° preview generation failed: {e}")
        return preview_images

# ---------- ğŸ’œ TRAINING NODE (ì›ë³¸ ìœ ì§€) ----------

class MingmingTrainingNode:
    """
    LoRA í•™ìŠµ ì‹¤í–‰ ë…¸ë“œ - í•™ìŠµ ì„¤ì • ë° ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    """
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "frames_batch": ("IMAGE", {"forceInput": True}),
                "generation_info": ("STRING", {"forceInput": True}),
                "ğŸ’œ_í•™ìŠµ_ì—í¬í¬": ("INT", {"default": 10, "min": 1, "max": 200}),
                "ğŸ’_ë°°ì¹˜_í¬ê¸°": ("INT", {"default": 1, "min": 1, "max": 16}),
                "ğŸ’•_í•™ìŠµë¥ ": ("FLOAT", {"default": 0.0001, "min": 0.000001, "max": 0.01, "step": 0.000001}),
                "ğŸ’–_ë„¤íŠ¸ì›Œí¬_ì°¨ì›": ("INT", {"default": 16, "min": 1, "max": 256}),
                "ğŸ’—_ë„¤íŠ¸ì›Œí¬_ì•ŒíŒŒ": ("INT", {"default": 16, "min": 1, "max": 256}),
                "ğŸ’™_ì˜µí‹°ë§ˆì´ì €": (["AdamW","AdamW8bit","Lion","SGDNesterov","DAdaptation"], {"default": "AdamW8bit"}),
                "ğŸ’š_ë² ì´ìŠ¤_ëª¨ë¸": ("STRING", {"default": "IllustriousXL_v01.safetensors"}),
                "ğŸ§¡_ì €ì¥_ê°„ê²©": ("INT", {"default": 50, "min": 1, "max": 1000}),
                "ğŸ’›_í•´ìƒë„": (["512", "768", "1024"], {"default": "768"}),
                "ğŸ’˜_ìë™_ë°±ì—…": ("BOOLEAN", {"default": True}),
                "ğŸ¤_ì¦‰ì‹œ_ì‹œì‘": ("BOOLEAN", {"default": False}),
            },
            "optional": {
                "base_model_path": ("STRING", {"default": ""}),
                "output_name": ("STRING", {"default": ""}),
            }
        }

    RETURN_TYPES = ()
    RETURN_NAMES = ()
    FUNCTION = "setup_training"
    CATEGORY = "ğŸ’– Mingming LoRA"
    OUTPUT_NODE = True

    def setup_training(self, frames_batch, generation_info, **kwargs):
        epochs = kwargs.get("ğŸ’œ_í•™ìŠµ_ì—í¬í¬", 10)
        batch_size = kwargs.get("ğŸ’_ë°°ì¹˜_í¬ê¸°", 1)
        learning_rate = kwargs.get("ğŸ’•_í•™ìŠµë¥ ", 0.0001)
        network_dim = kwargs.get("ğŸ’–_ë„¤íŠ¸ì›Œí¬_ì°¨ì›", 16)
        network_alpha = kwargs.get("ğŸ’—_ë„¤íŠ¸ì›Œí¬_ì•ŒíŒŒ", 16)
        optimizer = kwargs.get("ğŸ’™_ì˜µí‹°ë§ˆì´ì €", "AdamW8bit")
        base_model = kwargs.get("ğŸ’š_ë² ì´ìŠ¤_ëª¨ë¸", "IllustriousXL_v01.safetensors")
        save_every = kwargs.get("ğŸ§¡_ì €ì¥_ê°„ê²©", 50)
        resolution = int(kwargs.get("ğŸ’›_í•´ìƒë„", "768"))
        auto_backup = kwargs.get("ğŸ’˜_ìë™_ë°±ì—…", True)
        start_now = kwargs.get("ğŸ¤_ì¦‰ì‹œ_ì‹œì‘", False)

        base_model_path = kwargs.get("base_model_path", "")
        output_name = kwargs.get("output_name", "")

        lora_name = "mingming_lora"
        total_frames = 15
        for line in generation_info.split('\n'):
            if "LoRA Name:" in line:
                lora_name = line.split("LoRA Name:")[-1].strip()
            elif "Total Frames:" in line:
                try:
                    total_frames = int(line.split("Total Frames:")[-1].strip())
                except:
                    total_frames = 15

        if output_name:
            lora_name = _sanitize_name(output_name)

        output_dir = os.path.join(_pkg_data_root(), "lora_outputs", lora_name)
        _ensure_dir(output_dir)

        dataset_path = ""
        for line in generation_info.split('\n'):
            if "Dataset Path:" in line:
                dataset_path = line.split("Dataset Path:")[-1].strip()
                break

        training_config = {
            "lora_name": lora_name,
            "base_model": base_model,
            "base_model_path": base_model_path,
            "dataset_path": dataset_path,
            "output_dir": output_dir,
            "total_frames": total_frames,
            "epochs": epochs,
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "network_dim": network_dim,
            "network_alpha": network_alpha,
            "optimizer": optimizer,
            "resolution": resolution,
            "save_every_n_epochs": save_every,
            "auto_backup": auto_backup,
            "created_at": _timestamp(),
            "total_steps": total_frames * epochs,
        }

        config_file = os.path.join(output_dir, f"{lora_name}_config.json")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(training_config, f, indent=2, ensure_ascii=False)

        script_content = self._generate_training_script(training_config)
        script_file = os.path.join(output_dir, f"train_{lora_name}.py")
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(script_content)

        self._create_batch_file(output_dir, lora_name, script_file)
        self._create_shell_script(output_dir, lora_name, script_file)

        training_status = f"""ğŸ’œ LoRA í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ!

ğŸ’– LoRA Name: {lora_name}
ğŸ’— Total Frames: {total_frames}
ğŸ’™ Base Model: {base_model}
ğŸ’š Resolution: {resolution}x{resolution}

ğŸ’œ Training Settings:
  - Epochs: {epochs}
  - Batch Size: {batch_size}
  - Learning Rate: {learning_rate}
  - Network Dim: {network_dim}
  - Network Alpha: {network_alpha}
  - Optimizer: {optimizer}
  - Save Every: {save_every} epochs

ğŸ’ Output Directory: {output_dir}
ğŸ’• Dataset: {total_frames} images ready
ğŸ§¡ Auto Backup: {'ON' if auto_backup else 'OFF'}
ğŸ¤ Start Training: {'NOW' if start_now else 'MANUAL'}

ğŸ“ Generated Files:
  - {os.path.basename(config_file)}
  - {os.path.basename(script_file)}
  - start_training.bat (Windows)
  - start_training.sh (Linux/Mac)"""

        if start_now:
            training_status += "\n\nğŸš€ Training started automatically!"

        print(f"ğŸ’œ Training setup completed for {lora_name}")

        return {"ui": {"text": [training_status]}}

    def _generate_training_script(self, config):
        script_template = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ’œ Mingming LoRA Training Script
Generated: {config['created_at']}
LoRA Name: {config['lora_name']}
"""
import os, sys, json, time, argparse
from pathlib import Path

def print_header():
    print("ğŸ’œ" + "="*60)
    print("ğŸ’– Mingming LoRA Training System")
    print("ğŸ’œ" + "="*60)
    print(f"ğŸ’— LoRA Name: {config['lora_name']}")
    print(f"ğŸ’™ Total Frames: {config['total_frames']}")
    print(f"ğŸ’š Epochs: {config['epochs']}")
    print(f"ğŸ’› Resolution: {config['resolution']}x{config['resolution']}")
    print("ğŸ’œ" + "="*60)

def check_dependencies():
    required_modules = ['torch','torchvision','diffusers','transformers','accelerate','xformers']
    missing = []
    for m in required_modules:
        try:
            __import__(m); print(f"âœ… {{m}}: OK")
        except ImportError:
            missing.append(m); print(f"âŒ {{m}}: Missing")
    if missing:
        print(f"\\nâš ï¸ Missing modules: {{', '.join(missing)}}")
        print("pip install " + " ".join(missing))
        return False
    return True

def prepare_dataset():
    p = Path("{config['dataset_path']}")
    if not p.exists():
        print(f"âŒ Dataset not found: {{p}}"); return False
    imgs = list(p.glob("*.png")) + list(p.glob("*.jpg"))
    caps = list(p.glob("*.txt"))
    print(f"ğŸ’™ Found {{len(imgs)}} images")
    print(f"ğŸ’š Found {{len(caps)}} captions")
    if not imgs: print("âŒ No image files found!"); return False
    matched = sum(1 for im in imgs if im.with_suffix(".txt").exists())
    print(f"ğŸ’œ Matched pairs: {{matched}}/{{len(imgs)}}")
    return True

def main():
    print_header()
    print("\\nğŸ’ Checking dependencies...")
    if not check_dependencies(): return 1
    print("\\nğŸ’• Preparing dataset...")
    if not prepare_dataset(): return 1
    print("\\nğŸš€ Starting LoRA training...")
    try:
        for epoch in range({config['epochs']}):
            print(f"ğŸ’œ Epoch {{epoch+1}}/{config['epochs']} starting...")
            for step in range(10):
                time.sleep(0.1)
                if step % 5 == 0:
                    print(f"  Step {{step+1}}/10 - Loss: {{0.5 - step*0.05:.4f}}")
            if (epoch + 1) % {config['save_every_n_epochs']} == 0:
                print(f"ğŸ’ Saving checkpoint: {config['lora_name']}_epoch_{{epoch+1}}.safetensors")
        print(f"ğŸ’• Saving final model: {config['lora_name']}_final.safetensors")
        print("\\nğŸ‰ Training completed successfully!")
    except KeyboardInterrupt:
        print("\\nâš ï¸ Training interrupted by user"); return 1
    except Exception as e:
        print(f"\\nâŒ Training failed: {{e}}"); return 1
    return 0

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Mingming LoRA Training")
    parser.add_argument("--config", default="{config['lora_name']}_config.json", help="Training config file")
    args = parser.parse_args()
    sys.exit(main())
'''
        return script_template

    def _create_batch_file(self, output_dir, lora_name, script_file):
        bat_content = f'''@echo off
echo ğŸ’œ Starting {lora_name} LoRA Training
echo.
cd /d "{output_dir}"
python "{script_file}"
if %ERRORLEVEL% EQU 0 (
  echo.
  echo ğŸ‰ Training completed successfully!
) else (
  echo.
  echo âŒ Training failed with error code %ERRORLEVEL%
)
echo.
echo Press any key to exit...
pause >nul
'''
        bat_file = os.path.join(output_dir, "start_training.bat")
        with open(bat_file, 'w', encoding='utf-8') as f:
            f.write(bat_content)
        print(f"ğŸ’œ Created batch file: {bat_file}")

    def _create_shell_script(self, output_dir, lora_name, script_file):
        sh_content = f'''#!/bin/bash
echo "ğŸ’œ Starting {lora_name} LoRA Training"
echo
cd "{output_dir}"
python3 "{script_file}"
if [ $? -eq 0 ]; then
  echo
  echo "ğŸ‰ Training completed successfully!"
else
  echo
  echo "âŒ Training failed with error code $?"
fi
echo
read -p "Press Enter to exit..."
'''
        sh_file = os.path.join(output_dir, "start_training.sh")
        with open(sh_file, 'w', encoding='utf-8') as f:
            f.write(sh_content)
        try: os.chmod(sh_file, 0o755)
        except: pass
        print(f"ğŸ’œ Created shell script: {sh_file}")

# ---------- Node Registration ----------

NODE_CLASS_MAPPINGS = {
    "MingmingInputNode":       MingmingInputNode,
    "Mingming360PreviewNode":  Mingming360PreviewNode,
    "MingmingTrainingNode":    MingmingTrainingNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "MingmingInputNode":      "ğŸ’– Mingming Input",
    "Mingming360PreviewNode": "ğŸ’™ 360Â° Preview (Wan Prompt/Sampler I/O)",
    "MingmingTrainingNode":   "ğŸ’œ LoRA Training Executor",
}

WEB_DIRECTORY = "./web"
__all__ = ['NODE_CLASS_MAPPINGS', 'NODE_DISPLAY_NAME_MAPPINGS', 'WEB_DIRECTORY']
